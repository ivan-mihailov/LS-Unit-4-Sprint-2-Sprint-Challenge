{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Autograded Notebook (Canvas & CodeGrade)\n",
    "\n",
    "This notebook will be automatically graded. It is designed to test your answers and award points for the correct answers. Following the instructions for each Task carefully.\n",
    "Instructions\n",
    "\n",
    "- **Download** this notebook as you would any other ipynb file \n",
    "- **Upload** to Google Colab or work locally (if you have that set-up)\n",
    "- **Delete** `raise NotImplementedError()`\n",
    "\n",
    "- **Write** your code in the `# YOUR CODE HERE` space\n",
    "\n",
    "\n",
    "- **Execute** the Test cells that contain assert statements - these help you check your work (others contain hidden tests that will be checked when you submit through Canvas)\n",
    "\n",
    "- **Save** your notebook when you are finished\n",
    "- **Download** as a ipynb file (if working in Colab)\n",
    "- **Upload** your complete notebook to Canvas (there will be additional instructions in Slack and/or Canvas)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## *Data Science Unit 4 Sprint 2*\n",
    "\n",
    "# Sprint Challenge - Neural Network Foundations\n",
    "\n",
    "Table of Problems\n",
    "\n",
    "1. [Defining Neural Networks](#Q1)\n",
    "2. [Simple Perceptron](#Q2)\n",
    "    - Perceptron\n",
    "    - Multilayer Perceptron (i.e. Neural Network)\n",
    "    - Analyze and Compare\n",
    "4. [Keras MMP](#Q3)\n",
    "\n",
    "\n",
    "____\n",
    "\n",
    "# Before you submit your notebook you must first\n",
    "\n",
    "1) Restart your notebook's Kernel\n",
    "\n",
    "2) Run all cells sequentially, from top to bottom, so that cell numbers are sequential numbers (i.e. 1,2,3,4,5...)\n",
    "- Easiest way to do this is to click on the **Cell** tab at the top of your notebook and select **Run All** from the drop down menu. \n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a2d017ba3200be3890c0b67eda283c48",
     "grade": false,
     "grade_id": "cell-621a8b86bacf295a",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "<a id=\"Q1\"></a>\n",
    "## 1. Defining Neural Networks \n",
    "\n",
    "Write *your own* definitions for the following terms:\n",
    "\n",
    "- **Neuron:**\n",
    "\n",
    "- **Input Layer:** \n",
    "\n",
    "- **Hidden Layer:** \n",
    "\n",
    "- **Output Layer:**\n",
    "\n",
    "- **Activation:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7233c31461609b21a7fc2651afb12632",
     "grade": true,
     "grade_id": "cell-6adae65226f09553",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "- **Neuron:** This is the building block of a neural network. It is a mathematical function that accepts inputs, their weights plus a bias term and then passes them through an activation function (such as sigmoid, ReLu, tanh, etc.) which determines whether the neuron will activate or not. If the neuron activates, it then passes the updated weights and bias to the next layer or to the final output layer to make a prediction. If the neuron does not activate, the data is not passed onto the next layer.\n",
    "- **Input Layer:** This is a collection of input neurons where the train/test data is passed to the neural network for analysis and prediction.\n",
    "- **Hidden Layer:** A collection of neurons that accept the input data, weights, and biases, passes them through the activation function and determines how the weights and biases must be adjusted in order to be passed to additional hidden layer(s) or to the output layer to make a prediction.\n",
    "- **Output Layer:** A collection of neurons that transforms the weights and biases from the last (or only) hidden layer into probabilities and makes a prediction based on those probabilities.\n",
    "- **Activation:** This is the function within each hidden layer and the output layer which transforms the weights and biases coming into the layer and determines the adjustments that need to be made for the model to learn and ultimately make a correct prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10aa095d3db59bfe47f9823cfd62f1ef",
     "grade": false,
     "grade_id": "cell-d64f1de9e9458dc7",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "- `Explain` how Back-propagation works \n",
    "- `Explain` how Gradient Descent works (mention the learning rate)\n",
    "- `Explain` how Back-propagation and Gradient Descent are related   \n",
    "\n",
    "Use your own words, but feel free to reference external materials for this question. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ceb3f64a4b1b18346decf75c8f5567d2",
     "grade": true,
     "grade_id": "cell-cef20b23d4e0b056",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "- **Back-propagation:** This is the process of updating the weights/biases of a neural network model in reverse order from the output layer through the prior hidden layers at the end of a training epoch. In the next epoch the weights/biases for neurons that were responsible for higher contribution to the overall loss of the neural network are lowered and the weights/biases for neurons that were responsible for lower contribution to the overall loss of the neural network are increased. This allows for more efficient learning of the model and should lead to lower overall loss and higher prediction accuracy.\n",
    "- **Gradient Descent:** Gradient is a derivative that takes on the form of a vector. A gradient points in the direction of the greatest change. Gradient Descent tries to reach the minimum of the loss function with respect to the parameters (weights/biases) using the derivatives calculated in the back-propagation. The easiest way would be to adjust the parameters by substracting its corresponding derivative multiplied by a learning rate, which regulates how much a model should move in the gradient direction. \n",
    "- **Back-propagation/Gradient Descent Relationship:** Gradient Descent tries to reach the minimum of the loss function for the model with respect to the parameters (weights/biases) using the derivatives calculated in the back-propagation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e040f3ddce6eb34b017f0eb685b202e6",
     "grade": false,
     "grade_id": "cell-e013d19857352d79",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Remember our Simple Perceptron Class from Monday. \n",
    "\n",
    "- Describe the process of making a prediction, i.e. how do you go from inputs to outputs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d746de6391012340f8548821850a621c",
     "grade": true,
     "grade_id": "cell-53c7cc36db9d7983",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "Data/signal is passed from the input layer to the hidden layers and ultimately to the output layer (which makes the prediction):\n",
    "- Each layer takes in inputs from the training data (or previous layer);\n",
    "- Multiplies each input by its corresponding weight;\n",
    "- Adds bias to this weighted sum of inputs and weights;\n",
    "- Sends this weighted sum + bias through an activation function (sigmoid, ReLu, tanh, etc.).\n",
    "- This final activated value is the data/signal that gets passed onto the next layer of the network.\n",
    "- When the signal reaches the output layer, it converts the weights + biases into probabilities and makes a prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Q2\"></a>\n",
    "## 2. Simple Perceptron\n",
    "\n",
    "In this question, you will build two neural networks using `Keras`. After you build these two models, compare the results of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Our Dataset\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "\"Use this X & y in the following 2 models\"\n",
    "X = rng.randn(300, 2)\n",
    "y = np.array(np.logical_xor(X[:, 0] > 0, X[:, 1] > 0), \n",
    "             dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This word is speled wrong. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Perceptron\n",
    "Construct a simple perceptron using Keras. \n",
    "\n",
    "Make sure to include the following in your model:\n",
    "- Add `1 dense layer` with a `single neuron` \n",
    "- Use a `sigmoid activation function`\n",
    "- Set `epochs` to 10 \n",
    "- Use the version of `crossentropy loss` that is appropriate for this data.\n",
    "\n",
    "Your model should be called `model1` and make sure to save the results of your fit statement to a variable called `h1`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67e9f7297eb22a79437494d713d74b71",
     "grade": false,
     "grade_id": "cell-427690628f9c900b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.7682 - accuracy: 0.5833 - val_loss: 0.8940 - val_accuracy: 0.4667\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7668 - accuracy: 0.5833 - val_loss: 0.8916 - val_accuracy: 0.4667\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7655 - accuracy: 0.5833 - val_loss: 0.8894 - val_accuracy: 0.4667\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7643 - accuracy: 0.5833 - val_loss: 0.8872 - val_accuracy: 0.4667\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7630 - accuracy: 0.5833 - val_loss: 0.8851 - val_accuracy: 0.4667\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7618 - accuracy: 0.5833 - val_loss: 0.8829 - val_accuracy: 0.4833\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7606 - accuracy: 0.5833 - val_loss: 0.8807 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7594 - accuracy: 0.5833 - val_loss: 0.8787 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7582 - accuracy: 0.5833 - val_loss: 0.8769 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7571 - accuracy: 0.5875 - val_loss: 0.8751 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# build and fit model\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Initialize model as a Keras Sequential model\n",
    "model1 =  Sequential()\n",
    "\n",
    "# Add one Dense hidden layer with a single neuron with a \n",
    "# sigmoid activation function\n",
    "model1.add(Dense(1, input_dim = X.shape[1], activation = 'sigmoid'))\n",
    "\n",
    "# Compile model using binary_crossentropy for loss function (2 classes only)\n",
    "model1.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = 'accuracy')\n",
    "\n",
    "# Fir model for 10 epochs\n",
    "h1 = model1.fit(X, y, epochs = 10, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36f7f830036d0443ca8e8ba0f17b2a4e",
     "grade": true,
     "grade_id": "cell-bf2ae566afacde8c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Visible test\n",
    "assert len(model1.get_config()[\"layers\"]) == 2, \"Make sure you only create 1 Dense layer.\"\n",
    "assert len(h1.epoch) <=10, \"Did you make sure to set epochs to 10 or less?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class_name': 'InputLayer',\n",
       "  'config': {'batch_input_shape': (None, 2),\n",
       "   'dtype': 'float32',\n",
       "   'sparse': False,\n",
       "   'ragged': False,\n",
       "   'name': 'dense_input'}},\n",
       " {'class_name': 'Dense',\n",
       "  'config': {'name': 'dense',\n",
       "   'trainable': True,\n",
       "   'batch_input_shape': (None, 2),\n",
       "   'dtype': 'float32',\n",
       "   'units': 1,\n",
       "   'activation': 'sigmoid',\n",
       "   'use_bias': True,\n",
       "   'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "    'config': {'seed': None}},\n",
       "   'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "   'kernel_regularizer': None,\n",
       "   'bias_regularizer': None,\n",
       "   'activity_regularizer': None,\n",
       "   'kernel_constraint': None,\n",
       "   'bias_constraint': None}}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.get_config()[\"layers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95d3ee2935a0de64f2a5a22460520e69",
     "grade": true,
     "grade_id": "cell-a957e14380b2f508",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden tests - you will see the results when you submit to Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron\n",
    "Now construct a multi-layer perceptron model (also known as a neural network). \n",
    "\n",
    "Your neural network `must` have: \n",
    "- `2` Hidden Layers\n",
    "- Select any number between `5-32` for the number of neurons in each hidden layers\n",
    "- Your pick of activation function and optimizer\n",
    "- Incorporate the `Callback function` below into your model\n",
    "- Set epochs to `100`\n",
    "- Your model should be called `model2` \n",
    "- Save the results of your fit statement to a variable called `h2`. \n",
    "- Use the version of `crossentropy loss` that is appropriate for this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback): \n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        # if model reaches 99% accuracy, training is terminated \n",
    "        acc_threshold = 0.99\n",
    "        if(logs.get('accuracy') > acc_threshold):   \n",
    "            self.model.stop_training = True\n",
    "            self.model.callback_used = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "314337f29c8cd7f38224a31687a86b12",
     "grade": false,
     "grade_id": "cell-77523c4c64743f16",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.7561 - accuracy: 0.5875 - val_loss: 0.8730 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7547 - accuracy: 0.5875 - val_loss: 0.8712 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7538 - accuracy: 0.5875 - val_loss: 0.8691 - val_accuracy: 0.5167\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7526 - accuracy: 0.5875 - val_loss: 0.8672 - val_accuracy: 0.5167\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7515 - accuracy: 0.5875 - val_loss: 0.8654 - val_accuracy: 0.5167\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7504 - accuracy: 0.5875 - val_loss: 0.8636 - val_accuracy: 0.5167\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7495 - accuracy: 0.5875 - val_loss: 0.8615 - val_accuracy: 0.5167\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7481 - accuracy: 0.5875 - val_loss: 0.8598 - val_accuracy: 0.5167\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7472 - accuracy: 0.5875 - val_loss: 0.8578 - val_accuracy: 0.5333\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7462 - accuracy: 0.5875 - val_loss: 0.8558 - val_accuracy: 0.5333\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7449 - accuracy: 0.5875 - val_loss: 0.8541 - val_accuracy: 0.5333\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7440 - accuracy: 0.5875 - val_loss: 0.8522 - val_accuracy: 0.5333\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7430 - accuracy: 0.5875 - val_loss: 0.8503 - val_accuracy: 0.5333\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7419 - accuracy: 0.5875 - val_loss: 0.8486 - val_accuracy: 0.5333\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7409 - accuracy: 0.5875 - val_loss: 0.8468 - val_accuracy: 0.5333\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7399 - accuracy: 0.5875 - val_loss: 0.8450 - val_accuracy: 0.5333\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7391 - accuracy: 0.5875 - val_loss: 0.8431 - val_accuracy: 0.5333\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7380 - accuracy: 0.5875 - val_loss: 0.8414 - val_accuracy: 0.5333\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7370 - accuracy: 0.5875 - val_loss: 0.8397 - val_accuracy: 0.5333\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7362 - accuracy: 0.5917 - val_loss: 0.8381 - val_accuracy: 0.5333\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7352 - accuracy: 0.5917 - val_loss: 0.8365 - val_accuracy: 0.5333\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7343 - accuracy: 0.5917 - val_loss: 0.8349 - val_accuracy: 0.5333\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7335 - accuracy: 0.5958 - val_loss: 0.8332 - val_accuracy: 0.5333\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7326 - accuracy: 0.5958 - val_loss: 0.8316 - val_accuracy: 0.5333\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7317 - accuracy: 0.5958 - val_loss: 0.8301 - val_accuracy: 0.5333\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7309 - accuracy: 0.5958 - val_loss: 0.8287 - val_accuracy: 0.5333\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7302 - accuracy: 0.5958 - val_loss: 0.8271 - val_accuracy: 0.5333\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7291 - accuracy: 0.5958 - val_loss: 0.8256 - val_accuracy: 0.5333\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7282 - accuracy: 0.6000 - val_loss: 0.8240 - val_accuracy: 0.5333\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7275 - accuracy: 0.6000 - val_loss: 0.8223 - val_accuracy: 0.5333\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7267 - accuracy: 0.6000 - val_loss: 0.8207 - val_accuracy: 0.5333\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7259 - accuracy: 0.6000 - val_loss: 0.8193 - val_accuracy: 0.5333\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7250 - accuracy: 0.6000 - val_loss: 0.8180 - val_accuracy: 0.5333\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7243 - accuracy: 0.6000 - val_loss: 0.8166 - val_accuracy: 0.5333\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7236 - accuracy: 0.6000 - val_loss: 0.8150 - val_accuracy: 0.5333\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7228 - accuracy: 0.6042 - val_loss: 0.8135 - val_accuracy: 0.5333\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7219 - accuracy: 0.6000 - val_loss: 0.8124 - val_accuracy: 0.5333\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7213 - accuracy: 0.6083 - val_loss: 0.8110 - val_accuracy: 0.5333\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7206 - accuracy: 0.6125 - val_loss: 0.8097 - val_accuracy: 0.5333\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7199 - accuracy: 0.6083 - val_loss: 0.8084 - val_accuracy: 0.5333\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7193 - accuracy: 0.6125 - val_loss: 0.8069 - val_accuracy: 0.5333\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7184 - accuracy: 0.6125 - val_loss: 0.8057 - val_accuracy: 0.5333\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7178 - accuracy: 0.6125 - val_loss: 0.8044 - val_accuracy: 0.5333\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7171 - accuracy: 0.6125 - val_loss: 0.8030 - val_accuracy: 0.5333\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7164 - accuracy: 0.6125 - val_loss: 0.8019 - val_accuracy: 0.5333\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7158 - accuracy: 0.6125 - val_loss: 0.8006 - val_accuracy: 0.5333\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7151 - accuracy: 0.6125 - val_loss: 0.7994 - val_accuracy: 0.5333\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7145 - accuracy: 0.6125 - val_loss: 0.7980 - val_accuracy: 0.5333\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7138 - accuracy: 0.6125 - val_loss: 0.7967 - val_accuracy: 0.5333\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7131 - accuracy: 0.6125 - val_loss: 0.7956 - val_accuracy: 0.5333\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7126 - accuracy: 0.6125 - val_loss: 0.7942 - val_accuracy: 0.5333\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7118 - accuracy: 0.6125 - val_loss: 0.7930 - val_accuracy: 0.5333\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7112 - accuracy: 0.6125 - val_loss: 0.7917 - val_accuracy: 0.5333\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7106 - accuracy: 0.6167 - val_loss: 0.7905 - val_accuracy: 0.5333\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7101 - accuracy: 0.6167 - val_loss: 0.7893 - val_accuracy: 0.5333\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7094 - accuracy: 0.6167 - val_loss: 0.7882 - val_accuracy: 0.5333\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7089 - accuracy: 0.6167 - val_loss: 0.7871 - val_accuracy: 0.5333\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7083 - accuracy: 0.6167 - val_loss: 0.7859 - val_accuracy: 0.5333\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7078 - accuracy: 0.6167 - val_loss: 0.7847 - val_accuracy: 0.5333\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7073 - accuracy: 0.6167 - val_loss: 0.7835 - val_accuracy: 0.5333\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7066 - accuracy: 0.6167 - val_loss: 0.7825 - val_accuracy: 0.5333\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7063 - accuracy: 0.6167 - val_loss: 0.7813 - val_accuracy: 0.5333\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7056 - accuracy: 0.6167 - val_loss: 0.7804 - val_accuracy: 0.5333\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7052 - accuracy: 0.6167 - val_loss: 0.7794 - val_accuracy: 0.5333\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7046 - accuracy: 0.6167 - val_loss: 0.7784 - val_accuracy: 0.5333\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7042 - accuracy: 0.6167 - val_loss: 0.7774 - val_accuracy: 0.5333\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7037 - accuracy: 0.6167 - val_loss: 0.7765 - val_accuracy: 0.5333\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7033 - accuracy: 0.6167 - val_loss: 0.7755 - val_accuracy: 0.5333\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7028 - accuracy: 0.6125 - val_loss: 0.7747 - val_accuracy: 0.5333\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7024 - accuracy: 0.6167 - val_loss: 0.7737 - val_accuracy: 0.5333\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7019 - accuracy: 0.6167 - val_loss: 0.7728 - val_accuracy: 0.5333\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7015 - accuracy: 0.6167 - val_loss: 0.7719 - val_accuracy: 0.5333\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.7041 - accuracy: 0.71 - 0s 4ms/step - loss: 0.7010 - accuracy: 0.6167 - val_loss: 0.7710 - val_accuracy: 0.5333\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7005 - accuracy: 0.6167 - val_loss: 0.7703 - val_accuracy: 0.5333\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.7002 - accuracy: 0.6250 - val_loss: 0.7693 - val_accuracy: 0.5333\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6997 - accuracy: 0.6333 - val_loss: 0.7685 - val_accuracy: 0.5333\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6994 - accuracy: 0.6333 - val_loss: 0.7677 - val_accuracy: 0.5333\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6990 - accuracy: 0.6333 - val_loss: 0.7668 - val_accuracy: 0.5333\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6986 - accuracy: 0.6333 - val_loss: 0.7660 - val_accuracy: 0.5333\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6983 - accuracy: 0.6333 - val_loss: 0.7652 - val_accuracy: 0.5333\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6980 - accuracy: 0.6333 - val_loss: 0.7645 - val_accuracy: 0.5333\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6975 - accuracy: 0.6333 - val_loss: 0.7638 - val_accuracy: 0.5333\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6973 - accuracy: 0.6333 - val_loss: 0.7630 - val_accuracy: 0.5333\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6969 - accuracy: 0.6333 - val_loss: 0.7622 - val_accuracy: 0.5333\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6966 - accuracy: 0.6333 - val_loss: 0.7614 - val_accuracy: 0.5333\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6962 - accuracy: 0.6333 - val_loss: 0.7606 - val_accuracy: 0.5333\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6959 - accuracy: 0.6333 - val_loss: 0.7598 - val_accuracy: 0.5333\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6956 - accuracy: 0.6333 - val_loss: 0.7591 - val_accuracy: 0.5333\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6952 - accuracy: 0.6333 - val_loss: 0.7584 - val_accuracy: 0.5333\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6949 - accuracy: 0.6333 - val_loss: 0.7577 - val_accuracy: 0.5333\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6947 - accuracy: 0.6333 - val_loss: 0.7567 - val_accuracy: 0.5333\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6943 - accuracy: 0.6333 - val_loss: 0.7560 - val_accuracy: 0.5333\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6939 - accuracy: 0.6333 - val_loss: 0.7552 - val_accuracy: 0.5333\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6936 - accuracy: 0.6333 - val_loss: 0.7544 - val_accuracy: 0.5333\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6333 - val_loss: 0.7537 - val_accuracy: 0.5333\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6930 - accuracy: 0.6333 - val_loss: 0.7531 - val_accuracy: 0.5333\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6928 - accuracy: 0.6333 - val_loss: 0.7523 - val_accuracy: 0.5333\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6925 - accuracy: 0.6333 - val_loss: 0.7519 - val_accuracy: 0.5333\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.6333 - val_loss: 0.7512 - val_accuracy: 0.5333\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6919 - accuracy: 0.6333 - val_loss: 0.7505 - val_accuracy: 0.5333\n"
     ]
    }
   ],
   "source": [
    "# build and fit model\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Initialize model as a Keras Sequential model\n",
    "model2 =  Sequential()\n",
    "\n",
    "# Instatiate a custom callback\n",
    "callback = myCallback()\n",
    "\n",
    "# Add 2 Dense hidden layers with 32/16 neurons with a \n",
    "# tanh activation function\n",
    "model2.add(Dense(32, input_dim = X.shape[1], activation = 'tanh'))\n",
    "model2.add(Dense(16, activation = 'tanh'))\n",
    "\n",
    "# Set up output layer with a sigmoid activation function (2 classes only)\n",
    "model2.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# Compile model using binary_crossentropy for loss function (2 classes only)\n",
    "model2.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = 'accuracy')\n",
    "\n",
    "# Fir model for 100 epochs\n",
    "h2 = model1.fit(X, y, \n",
    "                epochs = 100, \n",
    "                validation_split = 0.2, \n",
    "                callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a5f575f46f151f97f1cebc19a484bae",
     "grade": true,
     "grade_id": "cell-770612ca24334d8a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Visible test\n",
    "assert len(model2.get_config()[\"layers\"]) == 4, \"You should have 4 layers: Input, hidden 1, hidden 2, output.\"\n",
    "assert 5 <= model2.get_config()[\"layers\"][1][\"config\"][\"units\"] <= 32, \"You should have 5 - 32 units in hidden layer 1, but don't.\"\n",
    "assert 5 <= model2.get_config()[\"layers\"][2][\"config\"][\"units\"] <= 32, \"You should have 5 - 32 units in hidden layer 2, but don't.\"\n",
    "assert h2.params[\"epochs\"] == 100, \"You didn't set epochs to 100.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ca73d4d3d17897a570e19a8a97c050f",
     "grade": true,
     "grade_id": "cell-49b1bf7cce22b5b9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden tests - you will see the results when you submit to Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze and Compare\n",
    "\n",
    "**Before you Start**: You will need to install an additional library for this next segment. \n",
    "\n",
    "Install the package `mlxtend` into the environment you are using for the sprint challenge.\n",
    "\n",
    "You can install this package using the following statement in the terminal\n",
    "\n",
    "```python\n",
    "pip install mlxtend\n",
    "```\n",
    "\n",
    "Or you can install this package using the following statement in your notebook\n",
    "\n",
    "```python\n",
    "!pip install mlxtend\n",
    "```\n",
    "\n",
    "If you choose to install this package from within your notebook, be sure to delete the install statement afterwards so that CodeGrade doesn't try to install it and potentially crash. \n",
    "\n",
    "\n",
    "The cells below generate decision boundary plots of your models (`model1` & `model2`). Review the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 2), (300,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "\n",
    "for clf, hist, name, grd in zip([model1,model2], [h1, h2],['Perceptron', 'Multi-Layer Perceptron'],[1,2]):\n",
    "\n",
    "    ax = plt.subplot(1,2, grd)\n",
    "    fig = plot_decision_regions(X=X, y=y, clf=clf, legend=2)\n",
    "    title = f\"{name} with {hist.history['accuracy'][-1]:,.2f} Accuracy\"\n",
    "    plt.title(title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40c30e638b6defe125180b9832a675e2",
     "grade": false,
     "grade_id": "cell-b1bde9222e35b3fc",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "1) Why does the Perceptron (`model1`) only achieve about 50% accuracy? \n",
    "\n",
    "2) What is the architectural property of the Multi-Layer Perceptron that allows it to more accurately learn the relationship between X and y? \n",
    "- Hint: recall that each layer represents a vector space and they usually have a different number of dimensions, $\\mathbb{R}^N$.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e01b50ff508342b905c5a4cdbd7d2dc4",
     "grade": true,
     "grade_id": "cell-302694c508c8da0e",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE\n",
    "1. The single Perceptron (model1) only achieves about 50% accuracy because it only has 1 neuron and is essentially trying to fit a single line through data that is divided in four quarters.\n",
    "2. The Multi-Layer Perceptron (model2) allows it to more accurately learn the relationship between X and y because it has 2 hidden layers that allow it to better learn non-linear relationships in data (such as X and y). In addition, model2 was ran for more epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Keras MMP <a id=\"Q3\"></a>\n",
    "\n",
    "- Implement a Multilayer Perceptron architecture of your choosing using the Keras library. \n",
    "- Train your model and report its baseline accuracy. \n",
    "- Then `hyper-parameters tune two parameters each with no more than 2 values each`\n",
    "    - Due to limited computational resources on CodeGrade `DO NOT INCLUDE ADDITIONAL PARAMETERS OR VALUES PLEASE`\n",
    "- Report your optimized model's accuracy\n",
    "- Use the Heart Disease Dataset provided (binary classification)\n",
    "- Use an appropriate loss function for a binary classification task\n",
    "- Use an appropriate activation function on the final layer of your network.\n",
    "- Train your model using verbose output for ease of grading.\n",
    "- Use GridSearchCV to hyper-parameters tune your model. \n",
    "    - **Use `n_jobs` = 1**\n",
    "- When hyper-parameters tuning, show you work by adding code cells for each new experiment.\n",
    "- Report the accuracy for each combination of hyper-parameters as you test them so that we can easily see which resulted in the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>115</td>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "20    59    1   0       135   234    0        1      161      0      0.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "158   58    1   1       125   220    0        1      144      0      0.4   \n",
       "12    49    1   1       130   266    0        1      171      0      0.6   \n",
       "85    67    0   2       115   564    0        0      160      0      1.6   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "20       1   0     3       1  \n",
       "2        2   0     2       1  \n",
       "158      1   4     3       1  \n",
       "12       2   0     2       1  \n",
       "85       1   0     3       1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load data\n",
    "data_path = 'https://raw.githubusercontent.com/ryanleeallred/datasets/master/heart.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "22de1dc5d17d7a0bc674d082c33e8b65",
     "grade": false,
     "grade_id": "cell-85dc40f19f5a1d6b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create an input matrix named 'X' store it in a 2D numpy array\n",
    "\n",
    "# Create an output vector for the labels named 'Y', store it in 1D numpy array\n",
    "\n",
    "# YOUR CODE HERE\n",
    "X = np.array(df[['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', \n",
    "                 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']])\n",
    "Y = np.array(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 13)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "825d4f808810a2a8d6301d7453afe478",
     "grade": true,
     "grade_id": "cell-c17c686c974edc2e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Visible Testing\n",
    "assert X.shape[0] == 303, \"Did you drop/lose some rows in X? Did you properly load and split the data?\"\n",
    "assert X.shape[1] == 13, \"Did you drop/lose some columns in X? Did you properly load and split the data?\"\n",
    "assert len(Y)== 303, \"Did you drop/lose some rows in Y? Did you properly load and split the data?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "475835631ff6a34028443dbf604bd922",
     "grade": false,
     "grade_id": "cell-cfc5517cd0b6fa64",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a function named 'create_model' that returns a compiled keras model -  required for KerasClassifier\n",
    "# YOUR CODE HERE\n",
    "def create_model(n_layers, first_layer_nodes, act_func, opt):\n",
    "    \"\"\"\n",
    "    Creates a compiled Keras model with 3 hidden layers\n",
    "    \"\"\"\n",
    "    # Calculate the nodes for the last layer\n",
    "    last_layer_nodes = round((first_layer_nodes / n_layers))\n",
    "    \n",
    "    # Create a list of nodes for each layer and\n",
    "    # Loop through the node list decreasing the nodes in each layer proportionately\n",
    "    n_nodes = [first_layer_nodes]\n",
    "    nodes_dec = round((last_layer_nodes - first_layer_nodes)/ (n_layers-1))\n",
    "    \n",
    "    for j in range(0, n_layers - 1):\n",
    "        n_nodes.append((n_nodes[j] + nodes_dec))\n",
    "    \n",
    "    # Initialize model as a Keras Sequential model\n",
    "    model =  Sequential()\n",
    "    \n",
    "    # Add Dense hidden n_layers with appropriate nodes & activation function\n",
    "    for i in range(1, n_layers):\n",
    "        if i == 1:\n",
    "            model.add(Dense(first_layer_nodes, \n",
    "                            input_dim = X.shape[1], \n",
    "                            activation = act_func))\n",
    "        else:\n",
    "            model2.add(Dense(n_nodes[i-1], activation = act_func))\n",
    "\n",
    "    # Set up output layer with a sigmoid activation function (2 classes only)\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    # Compile model using binary_crossentropy for loss function (2 classes only)\n",
    "    model.compile(loss = 'binary_crossentropy', \n",
    "                  optimizer = opt, \n",
    "                  metrics = 'accuracy')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b906697afb0a3b52cd19e9548eae6a7",
     "grade": true,
     "grade_id": "cell-fac25126eaf1eee4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_model() missing 4 required positional arguments: 'n_layers', 'first_layer_nodes', 'act_func', and 'opt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28272/1151888106.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visible Testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow.python.keras.engine.sequential'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"create_model should return a keras model that was created using the Sequential class.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: create_model() missing 4 required positional arguments: 'n_layers', 'first_layer_nodes', 'act_func', and 'opt'"
     ]
    }
   ],
   "source": [
    "# Visible Testing\n",
    "assert create_model().__module__ == 'tensorflow.python.keras.engine.sequential', \"create_model should return a keras model that was created using the Sequential class.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0412c74b7803790452d4914d99995dd2",
     "grade": false,
     "grade_id": "cell-fbc3d0a07230078c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Pass 'create_model' into KerasClassifier, store KerasClassifier to a variable named 'model'\n",
    "# YOUR CODE HERE\n",
    "model = KerasClassifier(build_fn = create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0442c29a94065e922c5ae929976a52ab",
     "grade": true,
     "grade_id": "cell-464e7506993775f2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "model should be a instance of KerasClassifier.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28272/3691526007.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visible Testing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow.python.keras.wrappers.scikit_learn'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model should be a instance of KerasClassifier.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: model should be a instance of KerasClassifier."
     ]
    }
   ],
   "source": [
    "# Visible Testing\n",
    "assert model.__module__ == 'tensorflow.python.keras.wrappers.scikit_learn', \"model should be a instance of KerasClassifier.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.7578 - accuracy: 0.5496 - val_loss: 0.7124 - val_accuracy: 0.5246\n",
      "Epoch 2/5\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5537 - val_loss: 0.6836 - val_accuracy: 0.5246\n",
      "Epoch 3/5\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6802 - accuracy: 0.5331 - val_loss: 0.6633 - val_accuracy: 0.5246\n",
      "Epoch 4/5\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6700 - accuracy: 0.5496 - val_loss: 0.6485 - val_accuracy: 0.6885\n",
      "Epoch 5/5\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6655 - accuracy: 0.5909 - val_loss: 0.6487 - val_accuracy: 0.7377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a76a13b580>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = create_model(n_layers = 3, \n",
    "                          first_layer_nodes =100, \n",
    "                          act_func = 'sigmoid', \n",
    "                          opt = 'sgd')\n",
    "\n",
    "base_model.fit(X, Y, epochs =5, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6603 - accuracy: 0.6634\n",
      "Baseline Model Accuracy is: 0.6634\n"
     ]
    }
   ],
   "source": [
    "print(f'Baseline Model Accuracy is: {base_model.evaluate(X, Y)[1]:2.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f88603ef37a4d3d2ef8699a41ac9a0b2",
     "grade": false,
     "grade_id": "cell-985c0425f3b1304d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the grid search parameters inside a dictionary named 'param_grid' \n",
    "# Use 2 hyper-parameters with 2 possible values for each \n",
    "\n",
    "# YOUR CODE HERE\n",
    "\"\"\"\n",
    "Because create_model as written requires 4 arguments,param_grid has to \n",
    "include 4 arguments even though it only tests 2 arguments for the GridSearch.\n",
    "This means the test in the cell below will fail.\n",
    "\"\"\"\n",
    "param_grid = {'n_layers': [5, 10],\n",
    "              'first_layer_nodes': [256, 512],\n",
    "              'act_func': ['tanh'], \n",
    "              'opt': ['adam']\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a551fd8278b30c1318c036f6ad43b503",
     "grade": true,
     "grade_id": "cell-c765b5db5489d7a2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Did you create a param dict with 2 hyper-parameters as keys?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28272/659977840.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Did you create a param dict with 2 hyper-parameters as keys?\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: Did you create a param dict with 2 hyper-parameters as keys?"
     ]
    }
   ],
   "source": [
    "assert len(param_grid.keys()) == 2, \"Did you create a param dict with 2 hyper-parameters as keys?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ea6312f4bc1f42809196b696037dd52",
     "grade": false,
     "grade_id": "cell-7cfb4315eab5031c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6477 - accuracy: 0.6485\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5895 - accuracy: 0.6980\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5853 - accuracy: 0.6980\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5656 - accuracy: 0.7178\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7228\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5682 - accuracy: 0.7030\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6648 - accuracy: 0.5941\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5776 - accuracy: 0.7129\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5713 - accuracy: 0.7178\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.6782\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.7178\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6355 - accuracy: 0.7030\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7218 - accuracy: 0.5891\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6405 - accuracy: 0.6139\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6161 - accuracy: 0.6139\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5998 - accuracy: 0.6733\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5792 - accuracy: 0.7178\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.7129\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8684 - accuracy: 0.3713\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6792 - accuracy: 0.5347\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6364 - accuracy: 0.6436\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6119 - accuracy: 0.6634\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6146 - accuracy: 0.6485\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5975 - accuracy: 0.6931\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7875 - accuracy: 0.4901\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6390 - accuracy: 0.6238\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5759 - accuracy: 0.6931\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5824 - accuracy: 0.7178\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5639 - accuracy: 0.7030\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6452 - accuracy: 0.6733\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5842\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 852us/step - loss: 0.6435 - accuracy: 0.6683\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 0s/step - loss: 0.6261 - accuracy: 0.6337\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6028 - accuracy: 0.6832\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1000us/step - loss: 0.5857 - accuracy: 0.6980\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5764 - accuracy: 0.7030\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6576 - accuracy: 0.5891\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5849 - accuracy: 0.6931\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5647 - accuracy: 0.7178\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5496 - accuracy: 0.7178\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7426\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5649 - accuracy: 0.6931\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7256 - accuracy: 0.5495\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5952 - accuracy: 0.6683\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5575 - accuracy: 0.7129\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5477 - accuracy: 0.7079\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7178\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6320 - accuracy: 0.7030\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7070 - accuracy: 0.5545\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6072 - accuracy: 0.6782\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5845 - accuracy: 0.7079\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 999us/step - loss: 0.5634 - accuracy: 0.7129\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5552 - accuracy: 0.7277\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.5662 - accuracy: 0.6436\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7409 - accuracy: 0.5248\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6556 - accuracy: 0.6337\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5838 - accuracy: 0.7030\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.6683\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 999us/step - loss: 0.5485 - accuracy: 0.7426\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5480 - accuracy: 0.7129\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7041 - accuracy: 0.5149\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5818 - accuracy: 0.7030\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5763 - accuracy: 0.6733\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 833us/step - loss: 0.5901 - accuracy: 0.6782\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5523 - accuracy: 0.7079\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6555 - accuracy: 0.6733\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6853 - accuracy: 0.5693\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6301 - accuracy: 0.6436\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5817 - accuracy: 0.6980\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5711 - accuracy: 0.7277\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5565 - accuracy: 0.7030\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5574 - accuracy: 0.6535\n",
      "Epoch 1/5\n",
      "10/10 [==============================] - 0s 1000us/step - loss: 0.8369 - accuracy: 0.5182\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6443 - accuracy: 0.6205\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 997us/step - loss: 0.6159 - accuracy: 0.6337\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5969 - accuracy: 0.6964\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5835 - accuracy: 0.7063\n"
     ]
    }
   ],
   "source": [
    "# Create Grid Search object and name it 'gs'\n",
    "# Run Grid Search \n",
    "# YOUR CODE HERE\n",
    "gs = GridSearchCV(estimator = model,\n",
    "                 param_grid = param_grid,\n",
    "                 n_jobs = 1,\n",
    "                 cv = 3)\n",
    "\n",
    "grid_result = gs.fit(X, Y, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7062706549962362 using {'act_func': 'tanh', 'first_layer_nodes': 256, 'n_layers': 5, 'opt': 'adam'}\n",
      "Means: 0.7062706549962362, Stdev: 0.004667370101995412 with: {'act_func': 'tanh', 'first_layer_nodes': 256, 'n_layers': 5, 'opt': 'adam'}\n",
      "Means: 0.6897689700126648, Stdev: 0.012348721806606915 with: {'act_func': 'tanh', 'first_layer_nodes': 256, 'n_layers': 10, 'opt': 'adam'}\n",
      "Means: 0.6798679828643799, Stdev: 0.0259868345848983 with: {'act_func': 'tanh', 'first_layer_nodes': 512, 'n_layers': 5, 'opt': 'adam'}\n",
      "Means: 0.6798679828643799, Stdev: 0.024697427683176756 with: {'act_func': 'tanh', 'first_layer_nodes': 512, 'n_layers': 10, 'opt': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "# your grid_result object should be able to run in this code \n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch No. 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn = create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Because create_model as written requires 4 arguments,param_grid has to \n",
    "include 4 arguments even though it only tests 2 arguments for the GridSearch.\n",
    "\"\"\"\n",
    "param_grid = {'n_layers': [3, 7],\n",
    "              'first_layer_nodes': [32, 128],\n",
    "              'act_func': ['tanh'], \n",
    "              'opt': ['adam']\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.5248\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6938 - accuracy: 0.5396\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6684 - accuracy: 0.5396\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6561 - accuracy: 0.5941\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1000us/step - loss: 0.6476 - accuracy: 0.6634\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.6931\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.1091 - accuracy: 0.4604\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9686 - accuracy: 0.4604\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1000us/step - loss: 0.8638 - accuracy: 0.4653\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7756 - accuracy: 0.4752\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7111 - accuracy: 0.5495\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6778 - accuracy: 0.5545\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7000 - accuracy: 0.5743\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5743\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6860 - accuracy: 0.5743\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6824 - accuracy: 0.5050\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6765 - accuracy: 0.5644\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7232 - accuracy: 0.5050\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0627 - accuracy: 0.5198\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9509 - accuracy: 0.5198\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 833us/step - loss: 0.8550 - accuracy: 0.5198\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8072 - accuracy: 0.5099\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7851 - accuracy: 0.4604\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7214 - accuracy: 0.5446\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8141 - accuracy: 0.4950\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7594 - accuracy: 0.5050\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7194 - accuracy: 0.5248\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6872 - accuracy: 0.5099\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6585 - accuracy: 0.5198\n",
      "4/4 [==============================] - 0s 984us/step - loss: 0.6819 - accuracy: 0.5248\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7658 - accuracy: 0.4257\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7106 - accuracy: 0.4257\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 833us/step - loss: 0.6598 - accuracy: 0.6683\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6418 - accuracy: 0.6980\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6309 - accuracy: 0.6881\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6346 - accuracy: 0.6931\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7191 - accuracy: 0.4950\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6750 - accuracy: 0.6040\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6448 - accuracy: 0.5842\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.6337\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6101 - accuracy: 0.6386\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6000 - accuracy: 0.6634\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6681 - accuracy: 0.5743\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6100 - accuracy: 0.6683\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6054 - accuracy: 0.6931\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5933 - accuracy: 0.7228\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1000us/step - loss: 0.5858 - accuracy: 0.6931\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.6139\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.7374 - accuracy: 0.4950\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.6386\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6200 - accuracy: 0.6634\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.7079\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1000us/step - loss: 0.5910 - accuracy: 0.6832\n",
      "4/4 [==============================] - 0s 999us/step - loss: 0.6103 - accuracy: 0.6535\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7209 - accuracy: 0.5248\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6588 - accuracy: 0.5941\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6152 - accuracy: 0.6436\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5994 - accuracy: 0.7030\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5814 - accuracy: 0.7129\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6057 - accuracy: 0.6733\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7978 - accuracy: 0.5198\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6471 - accuracy: 0.6188\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6225 - accuracy: 0.6485\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 993us/step - loss: 0.5786 - accuracy: 0.7129\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1000us/step - loss: 0.5692 - accuracy: 0.7079\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6263 - accuracy: 0.5941\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0067 - accuracy: 0.4257\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6678 - accuracy: 0.6040\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6626 - accuracy: 0.6040\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6508 - accuracy: 0.6337\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6239 - accuracy: 0.6584\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6186 - accuracy: 0.6436\n",
      "Epoch 1/5\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.8005 - accuracy: 0.5314\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 0s 1000us/step - loss: 0.6433 - accuracy: 0.6502\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6299 - accuracy: 0.6436\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6048 - accuracy: 0.6733\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5982 - accuracy: 0.6799\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(estimator = model,\n",
    "                 param_grid = param_grid,\n",
    "                 n_jobs = 1,\n",
    "                 cv = 3)\n",
    "\n",
    "grid_result = gs.fit(X, Y, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.6435643434524536 using {'act_func': 'tanh', 'first_layer_nodes': 128, 'n_layers': 3, 'opt': 'adam'}\n",
      "Means: 0.5841584205627441, Stdev: 0.07961936955087746 with: {'act_func': 'tanh', 'first_layer_nodes': 32, 'n_layers': 3, 'opt': 'adam'}\n",
      "Means: 0.5874587496121725, Stdev: 0.07511421310425327 with: {'act_func': 'tanh', 'first_layer_nodes': 32, 'n_layers': 7, 'opt': 'adam'}\n",
      "Means: 0.6435643434524536, Stdev: 0.021388576788767738 with: {'act_func': 'tanh', 'first_layer_nodes': 128, 'n_layers': 3, 'opt': 'adam'}\n",
      "Means: 0.636963685353597, Stdev: 0.032671590713967885 with: {'act_func': 'tanh', 'first_layer_nodes': 128, 'n_layers': 7, 'opt': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch No. 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn = create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Because create_model as written requires 4 arguments,param_grid has to \n",
    "include 4 arguments even though it only tests 2 arguments for the GridSearch.\n",
    "\"\"\"\n",
    "param_grid = {'n_layers': [5, 25],\n",
    "              'first_layer_nodes': [10, 300],\n",
    "              'act_func': ['tanh'], \n",
    "              'opt': ['adam']\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.5073 - accuracy: 0.5198\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4752 - accuracy: 0.5198\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4430 - accuracy: 0.5198\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4108 - accuracy: 0.5198\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3794 - accuracy: 0.5198\n",
      "4/4 [==============================] - 0s 988us/step - loss: 1.1622 - accuracy: 0.5941\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8673 - accuracy: 0.5396\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8474 - accuracy: 0.5396\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8296 - accuracy: 0.5396\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8141 - accuracy: 0.5396\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8010 - accuracy: 0.5396\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7653 - accuracy: 0.5545\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.5743\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6866 - accuracy: 0.5743\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 941us/step - loss: 0.6848 - accuracy: 0.5743\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.5743\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.5743\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7147 - accuracy: 0.4851\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7320 - accuracy: 0.5198\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7238 - accuracy: 0.5198\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7166 - accuracy: 0.5198\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7104 - accuracy: 0.5198\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7052 - accuracy: 0.5198\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.6753 - accuracy: 0.5941\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7165 - accuracy: 0.4604\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7008 - accuracy: 0.4604\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.4604\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6831 - accuracy: 0.4604\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6742 - accuracy: 0.4604\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6760 - accuracy: 0.4455\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8457 - accuracy: 0.4257\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7555 - accuracy: 0.4109\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7089 - accuracy: 0.4802\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6956 - accuracy: 0.5149\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6921 - accuracy: 0.5495\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.7210 - accuracy: 0.5644\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7038 - accuracy: 0.6040\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6446 - accuracy: 0.6535\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6421 - accuracy: 0.6188\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5970 - accuracy: 0.6782\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5871 - accuracy: 0.6782\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6227 - accuracy: 0.6535\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8172 - accuracy: 0.4356\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6016 - accuracy: 0.6733\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5893 - accuracy: 0.7079\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5687 - accuracy: 0.7030\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5480 - accuracy: 0.7178\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.6337\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8485 - accuracy: 0.5198\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6813 - accuracy: 0.6436\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6222 - accuracy: 0.6683\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.6881\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5837 - accuracy: 0.6881\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5908 - accuracy: 0.6634\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.5842\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6158 - accuracy: 0.6782\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5907 - accuracy: 0.6782\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5778 - accuracy: 0.6881\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5613 - accuracy: 0.6931\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6142 - accuracy: 0.6634\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6909 - accuracy: 0.5545\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5928 - accuracy: 0.6634\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5704 - accuracy: 0.7228\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5642 - accuracy: 0.6634\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5666 - accuracy: 0.7030\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6238\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9176 - accuracy: 0.4703\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.6961 - accuracy: 0.6040\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6235 - accuracy: 0.6337\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6066 - accuracy: 0.6584\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6007 - accuracy: 0.6634\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5900 - accuracy: 0.6634\n",
      "Epoch 1/5\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7032 - accuracy: 0.6106\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6176 - accuracy: 0.6634\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 1000us/step - loss: 0.5940 - accuracy: 0.6601\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5871 - accuracy: 0.6964\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5780 - accuracy: 0.6931\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(estimator = model,\n",
    "                 param_grid = param_grid,\n",
    "                 n_jobs = 1,\n",
    "                 cv = 3)\n",
    "\n",
    "grid_result = gs.fit(X, Y, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.6501650015513102 using {'act_func': 'tanh', 'first_layer_nodes': 300, 'n_layers': 5, 'opt': 'adam'}\n",
      "Means: 0.5445544620354971, Stdev: 0.0450105003472179 with: {'act_func': 'tanh', 'first_layer_nodes': 10, 'n_layers': 5, 'opt': 'adam'}\n",
      "Means: 0.5346534649531046, Stdev: 0.06416575795789252 with: {'act_func': 'tanh', 'first_layer_nodes': 10, 'n_layers': 25, 'opt': 'adam'}\n",
      "Means: 0.6501650015513102, Stdev: 0.012348700566578033 with: {'act_func': 'tanh', 'first_layer_nodes': 300, 'n_layers': 5, 'opt': 'adam'}\n",
      "Means: 0.6501650015513102, Stdev: 0.01866948040798165 with: {'act_func': 'tanh', 'first_layer_nodes': 300, 'n_layers': 25, 'opt': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch No. 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn = create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Because create_model as written requires 4 arguments,param_grid has to \n",
    "include 4 arguments even though it only tests 2 arguments for the GridSearch.\n",
    "\"\"\"\n",
    "param_grid = {'n_layers': [10],\n",
    "              'first_layer_nodes': [500],\n",
    "              'act_func': ['relu', 'elu'], \n",
    "              'opt': ['Nadam', 'RMSprop']\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7/7 [==============================] - 1s 1ms/step - loss: 2.9036 - accuracy: 0.4406\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8364 - accuracy: 0.4554\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.0142 - accuracy: 0.5990\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3057 - accuracy: 0.5743\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0029 - accuracy: 0.6287\n",
      "4/4 [==============================] - 0s 987us/step - loss: 1.3202 - accuracy: 0.5248\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.9136 - accuracy: 0.4604\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.7221 - accuracy: 0.5396\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0673 - accuracy: 0.5891\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9174 - accuracy: 0.6931\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.4849 - accuracy: 0.5743\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7029 - accuracy: 0.6931\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2708 - accuracy: 0.6089\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.7737 - accuracy: 0.5198\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2163 - accuracy: 0.5842\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 999us/step - loss: 1.2958 - accuracy: 0.6782\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3552 - accuracy: 0.6238\n",
      "4/4 [==============================] - 0s 995us/step - loss: 1.4962 - accuracy: 0.5545\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.4372 - accuracy: 0.5297\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 3.0555 - accuracy: 0.4752\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4258 - accuracy: 0.5099\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6798 - accuracy: 0.4703\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2771 - accuracy: 0.6485\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.3209 - accuracy: 0.6238\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.2160 - accuracy: 0.5990\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.4873 - accuracy: 0.4703\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.9020 - accuracy: 0.5941\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2071 - accuracy: 0.5347\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3446 - accuracy: 0.5347\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.9030 - accuracy: 0.6733\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.3986 - accuracy: 0.5446\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.0152 - accuracy: 0.5545\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.6075 - accuracy: 0.4950\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.2164 - accuracy: 0.5594\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.8992 - accuracy: 0.5149\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.4820 - accuracy: 0.6238\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2763 - accuracy: 0.5198\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3687 - accuracy: 0.5693\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3370 - accuracy: 0.6089\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3417 - accuracy: 0.5693\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3323 - accuracy: 0.6089\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.3015 - accuracy: 0.6436\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 1s 3ms/step - loss: 3.8040 - accuracy: 0.4505\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1498 - accuracy: 0.5990\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.9540 - accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1590 - accuracy: 0.6584\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9245 - accuracy: 0.6634\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.4504 - accuracy: 0.6733\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5151 - accuracy: 0.4257\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1857 - accuracy: 0.6139\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.5442 - accuracy: 0.5446\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4212 - accuracy: 0.5743\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4664 - accuracy: 0.5545\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.2279 - accuracy: 0.6040\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.6705 - accuracy: 0.4554\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.5296 - accuracy: 0.5594\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.3160 - accuracy: 0.5990\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1072 - accuracy: 0.5347\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.4274 - accuracy: 0.5644\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 2.1955 - accuracy: 0.5842\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 6.3746 - accuracy: 0.4307\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.0493 - accuracy: 0.5644\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2809 - accuracy: 0.6040\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.3181 - accuracy: 0.5248\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.5633 - accuracy: 0.4851\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0770 - accuracy: 0.6139\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 7.0746 - accuracy: 0.4455\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.1892 - accuracy: 0.5297\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.7900 - accuracy: 0.5446\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.6314 - accuracy: 0.5099\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.5250 - accuracy: 0.5644\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.5091 - accuracy: 0.5644\n",
      "Epoch 1/5\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 4.6581 - accuracy: 0.5215\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 0s 889us/step - loss: 3.1343 - accuracy: 0.5017\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 980us/step - loss: 1.7676 - accuracy: 0.5677\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.2056 - accuracy: 0.5677\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 2.1423 - accuracy: 0.5347\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(estimator = model,\n",
    "                 param_grid = param_grid,\n",
    "                 n_jobs = 1,\n",
    "                 cv = 3)\n",
    "\n",
    "grid_result = gs.fit(X, Y, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.6402640144030253 using {'act_func': 'relu', 'first_layer_nodes': 500, 'n_layers': 10, 'opt': 'RMSprop'}\n",
      "Means: 0.5907590786616007, Stdev: 0.07335347903298906 with: {'act_func': 'relu', 'first_layer_nodes': 500, 'n_layers': 10, 'opt': 'Nadam'}\n",
      "Means: 0.6402640144030253, Stdev: 0.023336850509977063 with: {'act_func': 'relu', 'first_layer_nodes': 500, 'n_layers': 10, 'opt': 'RMSprop'}\n",
      "Means: 0.6402640144030253, Stdev: 0.028390503971451875 with: {'act_func': 'elu', 'first_layer_nodes': 500, 'n_layers': 10, 'opt': 'Nadam'}\n",
      "Means: 0.5874587496121725, Stdev: 0.02034459460670113 with: {'act_func': 'elu', 'first_layer_nodes': 500, 'n_layers': 10, 'opt': 'RMSprop'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch No. 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn = create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Because create_model as written requires 4 arguments,param_grid has to \n",
    "include 4 arguments even though it only tests 2 arguments for the GridSearch.\n",
    "\"\"\"\n",
    "param_grid = {'n_layers': [10],\n",
    "              'first_layer_nodes': [500],\n",
    "              'act_func': ['relu', 'selu'], \n",
    "              'opt': ['Ftrl', 'Adamax']\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5212 - accuracy: 0.5495\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3956 - accuracy: 0.4901\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8547 - accuracy: 0.5644\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8289 - accuracy: 0.5545\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7192 - accuracy: 0.6139\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6369 - accuracy: 0.6634\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2220 - accuracy: 0.3960\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9767 - accuracy: 0.4802\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0166 - accuracy: 0.4851\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8543 - accuracy: 0.5198\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6990 - accuracy: 0.5644\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0044 - accuracy: 0.5644\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.6643 - accuracy: 0.5545\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8157 - accuracy: 0.5446\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7005 - accuracy: 0.5693\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6710 - accuracy: 0.6040\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7470 - accuracy: 0.5297\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6244 - accuracy: 0.6238\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.9249 - accuracy: 0.4802\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.3149 - accuracy: 0.5594\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0738 - accuracy: 0.6238\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8280 - accuracy: 0.6535\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6641 - accuracy: 0.7475\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6572 - accuracy: 0.7030\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.2879 - accuracy: 0.4802\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7540 - accuracy: 0.6040\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6591 - accuracy: 0.6386\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.6980\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6321 - accuracy: 0.7030\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8202 - accuracy: 0.6832\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 4.1986 - accuracy: 0.4752\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4689 - accuracy: 0.5792\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2520 - accuracy: 0.4851\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2370 - accuracy: 0.5891\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8744 - accuracy: 0.6089\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.8273 - accuracy: 0.5941\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2299 - accuracy: 0.4950\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8691 - accuracy: 0.4356\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3412 - accuracy: 0.4604\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9553 - accuracy: 0.4653\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9039 - accuracy: 0.5248\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1081 - accuracy: 0.4158\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.1244 - accuracy: 0.4604\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.2223 - accuracy: 0.4604\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8435 - accuracy: 0.4950\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7540 - accuracy: 0.6188\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6559 - accuracy: 0.5644\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6214 - accuracy: 0.6733\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 11.8286 - accuracy: 0.4406\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4956 - accuracy: 0.5050\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.4598 - accuracy: 0.5050\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2883 - accuracy: 0.4950\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.1273 - accuracy: 0.5644\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 1.3707 - accuracy: 0.4851\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 4.2632 - accuracy: 0.4851\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.8951 - accuracy: 0.4505\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7358 - accuracy: 0.6436\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6170 - accuracy: 0.6980\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1000us/step - loss: 0.7963 - accuracy: 0.6634\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.7215 - accuracy: 0.6535\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 7.7625 - accuracy: 0.4802\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.6732 - accuracy: 0.5495\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6649 - accuracy: 0.5743\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0467 - accuracy: 0.6386\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9126 - accuracy: 0.6337\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.8593 - accuracy: 0.7030\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.5368 - accuracy: 0.5396\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.2375 - accuracy: 0.4208\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.5014 - accuracy: 0.4851\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0847 - accuracy: 0.4851\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8863 - accuracy: 0.5693\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.8691 - accuracy: 0.6238\n",
      "Epoch 1/5\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 1.9833 - accuracy: 0.5050\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.6916 - accuracy: 0.6733\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 1000us/step - loss: 0.6620 - accuracy: 0.6898\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 1000us/step - loss: 0.5794 - accuracy: 0.7096\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5275 - accuracy: 0.7063\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(estimator = model,\n",
    "                 param_grid = param_grid,\n",
    "                 n_jobs = 1,\n",
    "                 cv = 3)\n",
    "\n",
    "grid_result = gs.fit(X, Y, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.6600660085678101 using {'act_func': 'relu', 'first_layer_nodes': 500, 'n_layers': 10, 'opt': 'Adamax'}\n",
      "Means: 0.6171617110570272, Stdev: 0.04068918921340226 with: {'act_func': 'relu', 'first_layer_nodes': 500, 'n_layers': 10, 'opt': 'Ftrl'}\n",
      "Means: 0.6600660085678101, Stdev: 0.04736865105500342 with: {'act_func': 'relu', 'first_layer_nodes': 500, 'n_layers': 10, 'opt': 'Adamax'}\n",
      "Means: 0.5247524678707123, Stdev: 0.10876076372872899 with: {'act_func': 'selu', 'first_layer_nodes': 500, 'n_layers': 10, 'opt': 'Ftrl'}\n",
      "Means: 0.6600660085678101, Stdev: 0.03267161680487577 with: {'act_func': 'selu', 'first_layer_nodes': 500, 'n_layers': 10, 'opt': 'Adamax'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch No. 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn = create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Because create_model as written requires 4 arguments,param_grid has to \n",
    "include 4 arguments even though it only tests 2 arguments for the GridSearch.\n",
    "\"\"\"\n",
    "param_grid = {'n_layers': [10],\n",
    "              'first_layer_nodes': [500],\n",
    "              'act_func': ['tanh', 'selu'], \n",
    "              'opt': ['adam', 'Adamax']\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7312 - accuracy: 0.5248\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6383 - accuracy: 0.6683\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5919 - accuracy: 0.6683\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5634 - accuracy: 0.7178\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7277\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5900 - accuracy: 0.7228\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8413 - accuracy: 0.5446\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5812 - accuracy: 0.6782\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5805 - accuracy: 0.6683\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5772 - accuracy: 0.6733\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5755 - accuracy: 0.6634\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6620 - accuracy: 0.6634\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7699 - accuracy: 0.5941\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6216 - accuracy: 0.6584\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.6832\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5952 - accuracy: 0.7079\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.7228\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.5503 - accuracy: 0.7228\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7971 - accuracy: 0.4109\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6320 - accuracy: 0.6188\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6049 - accuracy: 0.6733\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5865 - accuracy: 0.6980\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5775 - accuracy: 0.6931\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5770 - accuracy: 0.6832\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6760 - accuracy: 0.5396\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5881 - accuracy: 0.6782\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.6980\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5622 - accuracy: 0.6832\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7228\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6470 - accuracy: 0.6238\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7080 - accuracy: 0.5842\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.6337\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.6132 - accuracy: 0.6485\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.5884 - accuracy: 0.6881\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.6881\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5947 - accuracy: 0.6337\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.1065 - accuracy: 0.5446\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.2976 - accuracy: 0.5446\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9486 - accuracy: 0.6337\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.9389 - accuracy: 0.6337\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7300 - accuracy: 0.7079\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6653 - accuracy: 0.7030\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 3.7028 - accuracy: 0.5594\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 1.5325 - accuracy: 0.6188\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8540 - accuracy: 0.6485\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.8025 - accuracy: 0.6782\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.5826 - accuracy: 0.7228\n",
      "4/4 [==============================] - 0s 999us/step - loss: 0.6823 - accuracy: 0.6832\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 2.9838 - accuracy: 0.5248\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.3687 - accuracy: 0.5050\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7685 - accuracy: 0.6634\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6503 - accuracy: 0.7079\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.6802 - accuracy: 0.6683\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6026 - accuracy: 0.6535\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 2.0300 - accuracy: 0.5545\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8633 - accuracy: 0.6089\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.9667 - accuracy: 0.5941\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7019 - accuracy: 0.6881\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7451 - accuracy: 0.6733\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5989 - accuracy: 0.7030\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 5.3730 - accuracy: 0.4802\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6361 - accuracy: 0.5743\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8979 - accuracy: 0.6832\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7760 - accuracy: 0.6485\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.8309 - accuracy: 0.6584\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7665 - accuracy: 0.6733\n",
      "Epoch 1/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 6.0209 - accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.6196 - accuracy: 0.6188\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 1.0707 - accuracy: 0.5891\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7898 - accuracy: 0.7178\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.7644 - accuracy: 0.6634\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7542 - accuracy: 0.6436\n",
      "Epoch 1/5\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.7029 - accuracy: 0.5413\n",
      "Epoch 2/5\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5766 - accuracy: 0.7063\n",
      "Epoch 3/5\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5677 - accuracy: 0.7030\n",
      "Epoch 4/5\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5475 - accuracy: 0.7327\n",
      "Epoch 5/5\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 0.5432 - accuracy: 0.7195\n"
     ]
    }
   ],
   "source": [
    "gs = GridSearchCV(estimator = model,\n",
    "                 param_grid = param_grid,\n",
    "                 n_jobs = 1,\n",
    "                 cv = 3)\n",
    "\n",
    "grid_result = gs.fit(X, Y, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7029703060785929 using {'act_func': 'tanh', 'first_layer_nodes': 500, 'n_layers': 10, 'opt': 'adam'}\n",
      "Means: 0.7029703060785929, Stdev: 0.02800424870987148 with: {'act_func': 'tanh', 'first_layer_nodes': 500, 'n_layers': 10, 'opt': 'adam'}\n",
      "Means: 0.646864672501882, Stdev: 0.025986816922028384 with: {'act_func': 'tanh', 'first_layer_nodes': 500, 'n_layers': 10, 'opt': 'Adamax'}\n",
      "Means: 0.6798679828643799, Stdev: 0.020344617168058445 with: {'act_func': 'selu', 'first_layer_nodes': 500, 'n_layers': 10, 'opt': 'adam'}\n",
      "Means: 0.6732673247655233, Stdev: 0.024252390796650362 with: {'act_func': 'selu', 'first_layer_nodes': 500, 'n_layers': 10, 'opt': 'Adamax'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "Higest Accuracy achieved is 0.7063 with the following tuned hyperparameters:\n",
    "- 5 Dense hidden layers;\n",
    "- 256 first layer neurons;\n",
    "- a 'tanh' (Hyperbolic tangent) activation function; and\n",
    "- an 'adam' optimizer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
